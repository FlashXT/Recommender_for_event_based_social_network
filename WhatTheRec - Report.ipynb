{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Report\n",
    "# Project Name - WhatTheRec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Problem Statement\n",
    "In the present scenario, a plethora of events are being held daily at different places and different times. Hence, it is difficult for a user to keep track of all the events and choose between various events which to attend. The problem worsens because the users do not know which events would be interesting and relevant to them. Hence, it is important that an event sharing social network uses recommenders to suggest relevant and interesting events to its users which help them choose between various events. While recommending events, another problem which arises is that of unseen data(events). We do not know for sure which users will attend what events, especially in the case of new users. This is called the cold start problem. There are many Event Based Social Network (EBSN) websites like meetup.com, eventbrite.com etc., which could deploy this algorithm in order to successfully suggest interesting and relevant events to its users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Work\n",
    "There has been some work already done involving hybrid approaches in event recommendation by Minkov et al. [1]. This paper demonstrates collaborative filtering on a dataset of academic events. Our implementation of the recommender system follows [2], which also utilizes other signals such as a group of users, location, and temporal preferences. Khrouf and Troncy [3] for recommending music related events, utilized category information about different artists from a well-known source. But this approach fails when we do not have this information about every event, as events can be across different domains. Our implementation takes into account RSVP and group information and other contextual data. Recent works [4] have shown that pure matrix factorization (based only on user-event interactions) performs poorly on EBSN data in comparison to other methods due to a high level of the sparsity of these datasets. As per experiments carried out, state-of-the-art matrix factorization algorithms did not perform better than simple collaborative filtering algorithms such as user-based k-NN. Thus the focus is on considering the explicit features than the latent ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach & Methods\n",
    "\n",
    "Data Acquisition - Initially we fetched data from meetup.com using their public apis. As we started developing, we realized the data was too less as this data is super sparse in nature. So, when we again started getting data, they changed their apis and a lot of them were broken. So, we decided to contact the the authors of this paper and got the raw data from them. We cleaned/parsed the data and used that for our project. We used data from Jan 1, 2010 - Jan 2014. \n",
    "The data contains the following information:\n",
    "\n",
    "1. Events: event id, description of event, event group, users who rsvped to this event.\n",
    "2. Members: member id, lat long\n",
    "3. Groups: events organized by the group, members involved in the group\n",
    "\n",
    "We, then, divided the data into timestamps of 6 months. For example, one timestamp would be July 1, 2010. Then, the first 6 months were used for training and the last 6 months for testing. We extracted the following features to recommend events: time, location, description and group frequency of event. \n",
    "\n",
    "a. Content-based - We formed a model of a user using the description of the past events he attended. Then, we found similarity of potential events with the user model. \n",
    "\n",
    "b. Location-based - We, then, fit a gausian distribution to the location of the past events of a user. Then, we found the probability of new event according to the curve. \n",
    "\n",
    "c. Group-Frequency - The intuition here is that the likelihood of the target user attending an event depends on the number of events this user attended in the group that event belongs to. \n",
    "\n",
    "d. Time-Aware - Another important factor that affect users' decision on attending an event is when the event occurs. We capture this intuition by assuming that users that attended events in the past at certain days of the week and at certain hours of the day will likely attend events with a similar temporal profile in the future.\n",
    "\n",
    "Now, that we have built a model of the data, we then computed similarity scores for each member with the events that they had rsvp'd. Events in the first half were used to train the model and the events in the second half were used to test it. Note that we knew the events which the members had rsvp'd for the both the halves. So, the rsvp's for the second half were used to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can run our recommender code below. Type the name of cities you want to run the recommender on: \n",
    "Note: We have data from only Chicago, San jose and Phoenix. You can also change the number of members you want to train on. Additionally, you can use a list of ML algorithms as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Parameters Below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('src')\n",
    "city = 'LCHICAGO' # or 'LSAN JOSE', or 'LPHOENIX'\n",
    "algolist = ['rf'] #'svm', 'nb', 'mlp'\n",
    "number_of_members = 50 #100, 150 (not more than this, otherwise system would take too much memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "import argparse\n",
    "from partition import *\n",
    "from content.content_recommender import ContentRecommender\n",
    "from temporal.time_recommender import TimeRecommender\n",
    "from location.location_recommender import LocationRecommender\n",
    "from group_frequency.grp_freq_recommender import GrpFreqRecommender\n",
    "from hybrid.learning_to_rank import LearningToRank\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "#number of seconds in 6 months\n",
    "train_data_interval = ((364 / 2) * 24 * 60 * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Testing using Content Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def content_classifier(training_repo, test_repo, timestamp, simscores, test_members):\n",
    "\n",
    "    training_events_dict = training_repo['members_events']\n",
    "    potential_events = list(test_repo['events_info'].keys())\n",
    "\n",
    "    contentRecommender = ContentRecommender()\n",
    "    contentRecommender.train(training_events_dict, training_repo)\n",
    "    test_events_vec = contentRecommender.get_test_events_wth_description(test_repo, potential_events)\n",
    "\n",
    "    #TEST FOR BEST USERS\n",
    "    for member in test_members:\n",
    "         contentRecommender.test(member, potential_events, test_events_vec, simscores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Testing using Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_classifier(training_repo, test_repo, timestamp, simscores, test_members):\n",
    "\n",
    "    training_events_dict = training_repo['members_events']\n",
    "    potential_events = list(test_repo['events_info'].keys())\n",
    "\n",
    "    timeRecommender = TimeRecommender()\n",
    "    timeRecommender.train(training_events_dict, training_repo)\n",
    "    test_events_vec = timeRecommender.get_test_event_vecs_with_time(test_repo, potential_events)\n",
    "\n",
    "    #TEST FOR BEST USERS\n",
    "    for member in test_members:\n",
    "         timeRecommender.test(member, potential_events, test_events_vec, simscores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Testing using Location feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loc_classifier(training_repo, test_repo, timestamp, simscores, test_members):\n",
    "    training_events_dict = training_repo['members_events']\n",
    "    potential_events = list(test_repo['events_info'].keys())\n",
    "\n",
    "    locationRecommender = LocationRecommender()\n",
    "    locationRecommender.train(training_events_dict, training_repo)\n",
    "\n",
    "    #TEST FOR BEST USERS\n",
    "    for member in test_members:\n",
    "        locationRecommender.test(member, potential_events, test_repo, simscores)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Testing using Group Frequency feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def grp_freq_classifier(training_repo, test_repo, timestamp, simscores, test_members):\n",
    "    training_events_dict = training_repo['members_events']\n",
    "    potential_events = list(test_repo['events_info'].keys())\n",
    "\n",
    "    grp_freq_recommender = GrpFreqRecommender()\n",
    "    grp_freq_recommender.train(training_events_dict, training_repo)\n",
    "    \n",
    "    for member in test_members:\n",
    "         grp_freq_recommender.test(member, potential_events, test_repo, simscores)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, extract the data from csv file into python dictionaries. local_crawler.py does the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_and_run_local_crawler():\n",
    "    \n",
    "    if os.path.isdir(\"../crawler/cities/LCHICAGO\") and os.path.isdir(\"../crawler/cities/LSAN JOSE\")\\\n",
    "            and os.path.isdir(\"../crawler/cities/LPHOENIX\"):\n",
    "        if len(os.listdir(\"../crawler/cities/LCHICAGO\")) >= 5 and len(os.listdir(\"../crawler/cities/LSAN JOSE\"))>=5\\\n",
    "                and len(os.listdir(\"../crawler/cities/LPHOENIX\")) >= 5:\n",
    "            return\n",
    "        \n",
    "    # Run the local_crawler.py file    \n",
    "    os.chdir(\"../crawler\")\n",
    "    os.system(\"python local_crawler.py\")\n",
    "    os.chdir(\"../src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function generates the list of best users based on the number of RSVP's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_script(number_of_members):\n",
    "    os.chdir(\"scripts\")\n",
    "    os.system(\"python script.py --number \" + str(number_of_members))\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    check_and_run_local_crawler()\n",
    "    print \"Building best user database ...\"\n",
    "    run_script(number_of_members)\n",
    "    print \"Best users extracted.\"\n",
    "\n",
    "    \n",
    "    group_members, group_events, event_group = load_groups(\"../crawler/cities/\" + city + \"/group_members.json\",\n",
    "                                                            \"../crawler/cities/\" + city + \"/group_events.json\")\n",
    "    events_info = load_events(\"../crawler/cities/\" + city + \"/events_info.json\")\n",
    "    members_info = load_members(\"../crawler/cities/\" + city + \"/members_info.json\")\n",
    "    member_events = load_rsvps(\"../crawler/cities/\" + city + \"/rsvp_events.json\")\n",
    "\n",
    "    repo = dict()\n",
    "    repo['group_events'] = group_events\n",
    "    repo['group_members'] = group_members\n",
    "    repo['events_info'] = events_info\n",
    "    repo['members_info'] = members_info\n",
    "    repo['members_events'] = member_events\n",
    "    repo['event_group'] = event_group\n",
    "    \n",
    "    #simscores_across_features is a dictionary to store similarity score obtained for each feature\n",
    "    #for each member and for a given event. For example in case of content classifer we will\n",
    "    #access the similarity score as follows: simscores['content_classifier'][member_id][event_id].\n",
    "    #We will pass only a specific subdictionary (Ex: simscores['content_classifier']) to the\n",
    "    #classifier functions, which will work on them and populate them.\n",
    "    \n",
    "    simscores_across_features = defaultdict(lambda :defaultdict(lambda :defaultdict(lambda :0)))\n",
    "    hybrid_simscores = defaultdict(lambda :defaultdict(lambda :0))\n",
    "\n",
    "    start_time = 1262304000 # 1st Jan 2010\n",
    "    end_time = 1388534400 # 1st Jan 2014\n",
    "    timestamps = get_timestamps(start_time, end_time)\n",
    "    timestamps = sorted(timestamps, reverse=True)\n",
    "    count_partition = 1\n",
    "\n",
    "    f_temp = open('temp_result.txt', 'w+')\n",
    "    f_temp.write(\"Using classification algorithms : \" + str(algolist) + \" and number of members as : \" +\\\n",
    "                 str(number_of_members) + \"\\n\")\n",
    "\n",
    "    for t in timestamps:\n",
    "        start_time = t - train_data_interval\n",
    "        end_time = t + train_data_interval\n",
    "        test_members = []\n",
    "        f = open(\"scripts/\"+city + \"_best_users_\" + str(start_time) + \"_\" + str(end_time) + \".txt\", \"r\")\n",
    "        for users in f:\n",
    "            test_members.extend(users.split())\n",
    "        f.close()\n",
    "        test_members = test_members[:number_of_members]\n",
    "        print \"Partition at timestamp \", datetime.datetime.fromtimestamp(t), \" are : \"\n",
    "        training_repo, test_repo = get_partitioned_repo_wrapper(t, repo)\n",
    "        print \"Partitioned Repo retrieved for timestamp : \", datetime.datetime.fromtimestamp(t)\n",
    "\n",
    "        training_members = set(training_repo['members_events'].keys())\n",
    "        test_members =  training_members.intersection(set(test_members))\n",
    "        test_members = list(test_members)\n",
    "        \n",
    "        #Calling content based classifer train and test functions from here. Pass the repo\n",
    "        #as an argument to these functions.\n",
    "        start = time.clock()\n",
    "        print \"Starting Content Classifier\"\n",
    "        content_classifier(training_repo, test_repo, t, simscores_across_features['content_classifier'],\\\n",
    "                           test_members)\n",
    "        print \"Completed Content Classifier in \", time.clock() - start, \" seconds\"\n",
    "\n",
    "        start = time.clock()\n",
    "        print \"Starting Time Classifier\"\n",
    "        time_classifier(training_repo, test_repo, t, simscores_across_features['time_classifier'], test_members)\n",
    "        print \"Completed Time Classifier in \", time.clock() - start, \" seconds\"\n",
    "\n",
    "        start = time.clock()\n",
    "        print \"Starting Location Classifier\"\n",
    "        loc_classifier(training_repo, test_repo, t, simscores_across_features['location_classifier'], test_members)\n",
    "        print \"Completed Location Classifier in \", time.clock() - start, \" seconds\"\n",
    "\n",
    "        start = time.clock()\n",
    "        print \"Starting Group Frequency Classifier\"\n",
    "        grp_freq_classifier(training_repo, test_repo, t, simscores_across_features['grp_freq_classifier'],\\\n",
    "                            test_members)\n",
    "        print \"Completed Group Frequency Classifier in \", time.clock() - start, \" seconds\"\n",
    "\n",
    "        f_temp.write(\"============== Starting classification for partition : \" +  str(count_partition) + \" ===================\\n\")\n",
    "        print \"============== Starting classification for partition : \" +  str(count_partition) + \" ===================\"\n",
    "        learningToRank = LearningToRank()\n",
    "        learningToRank.learning(simscores_across_features, test_repo[\"events_info\"].keys(), \\\n",
    "                                test_repo[\"members_events\"], test_members, f_temp, algolist, \\\n",
    "                                number_of_members, count_partition)\n",
    "        f_temp.write(\"============== Completed classification for partition : \" +  str(count_partition) + \" ===================\\n\")\n",
    "        print \"============== Completed classification for partition : \" + str(count_partition) + \" ===================\"\n",
    "        \n",
    "        count_partition += 1\n",
    "    \n",
    "    f_temp.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We divided an year's data in 2 slots. So we build the model of the user from the rsvpd events in the first slot, and then for each of the event in the next slot, do the recommendation. We do a k fold setup to evaluate recommendations. For 80% of the users, we train the classifier and then calculate precision, recall and f-score for the remaining 20% of the users.\n",
    "\n",
    "For a new user(who didn't attend any event in the fist slot), we recommend the event which occurs closest to user's location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Results for Chicago:-</h3>\n",
    "<table>\n",
    "<tbody>\n",
    "<tr><th>Partition Number</th><th>Number of members</th><th>Precision</th><th>Recall</th><th>F-measure</th></tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\">1</td>\n",
    "<td>50</td>\n",
    "<td>0.695475638051</td>\n",
    "<td>0.872634643377</td>\n",
    "<td>0.774047772757</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.700596056855</td>\n",
    "<td>0.648556876061</td>\n",
    "<td>0.673572845493</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.537199542159</td>\n",
    "<td>0.529721595184</td>\n",
    "<td>0.533434362569</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\">\n",
    " 2</td>\n",
    "<td>50</td>\n",
    "<td>0.660746003552</td>\n",
    "<td>0.749244712991</td>\n",
    "<td>0.702218027371</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.498137307078</td>\n",
    "<td>0.484221417486</td>\n",
    "<td>0.491080797482</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.538929440389</td>\n",
    "<td>0.427812650893</td>\n",
    "<td>0.476985195155</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\">3</td>\n",
    "<td>50</td>\n",
    "<td>0.738186462324</td>\n",
    "<td>0.544256120527</td>\n",
    "<td>0.626558265583</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.667063020214</td>\n",
    "<td>0.270752895753</td>\n",
    "<td>0.385169927909</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.458050847458</td>\n",
    "<td>0.426598263615</td>\n",
    "<td>0.441765427054</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\">4</td>\n",
    "<td>50</td>\n",
    "<td>0.507448789572</td>\n",
    "<td>0.581023454158</td>\n",
    "<td>0.541749502982</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.660091047041</td>\n",
    "<td>0.26395631068</td>\n",
    "<td>0.37711313394</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.711198428291</td>\n",
    "<td>0.2145820984</td>\n",
    "<td>0.329690346084</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\">5</td>\n",
    "<td>50</td>\n",
    "<td>0.673548387097</td>\n",
    "<td>0.509765625</td>\n",
    "<td>0.580322401334</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.759791122715</td>\n",
    "<td>0.178199632578</td>\n",
    "<td>0.28869047619</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.518197573657</td>\n",
    "<td>0.19606557377</td>\n",
    "<td>0.28449096099</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\">6</td>\n",
    "<td>50</td>\n",
    "<td>0.712121212121</td>\n",
    "<td>0.488196411709</td>\n",
    "<td>0.579271708683</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.571045576408</td>\n",
    "<td>0.167189952904</td>\n",
    "<td>0.258652094718</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.545180722892</td>\n",
    "<td>0.209612044007</td>\n",
    "<td>0.302802174822</td>\n",
    "</tr>\n",
    " <tr>\n",
    "<td rowspan=\"3\">7</td>\n",
    "<td>50</td>\n",
    "<td>0.485947416138</td>\n",
    "<td>0.619653179191</td>\n",
    "<td>0.544715447154</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.563492063492</td>\n",
    "<td>0.214016578749</td>\n",
    "<td>0.310212998362</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.551656920078</td>\n",
    "<td>0.16915720263</td>\n",
    "<td>0.258920402562</td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Results for Pheonix:-</h3>\n",
    "<table>\n",
    "<tr>\n",
    "<th>\n",
    "Partition Number\n",
    "</th>\n",
    "<th>\n",
    "Number of members\n",
    "</th>\n",
    "<th>\n",
    "Precision\n",
    "</th>\n",
    "<th>\n",
    "Recall\n",
    "</th>\n",
    "<th>\n",
    "F-measure\n",
    "</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\">\n",
    "1\n",
    "</td>\n",
    "<td>\n",
    "50\n",
    "</td>\n",
    "<td>\n",
    "0.48322147651\n",
    "</td>\n",
    "<td>\n",
    "0.356435643564\n",
    "</td>\n",
    "<td>\n",
    "0.410256410256\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "100\n",
    "</td>\n",
    "<td>\n",
    "0.462082912032\n",
    "</td>\n",
    "<td>\n",
    "0.536594911937\n",
    "</td>\n",
    "<td>\n",
    "0.496559217675\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "150\n",
    "</td>\n",
    "<td>\n",
    "0.417532640554\n",
    "</td>\n",
    "<td>\n",
    "0.532630863358\n",
    "</td>\n",
    "<td>\n",
    "0.468110530246\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td rowspan=\"3\">\n",
    "2\n",
    "</td>\n",
    "<td>\n",
    "50\n",
    "</td>\n",
    "<td>\n",
    "0.76376146789\n",
    "</td>\n",
    "<td>\n",
    "0.256351039261\n",
    "</td>\n",
    "<td>\n",
    "0.38386167147\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "100\n",
    "</td>\n",
    "<td>\n",
    "0.499249249249\n",
    "</td>\n",
    "<td>\n",
    "0.348167539267\n",
    "</td>\n",
    "<td>\n",
    "0.410240592227\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "150\n",
    "</td>\n",
    "<td>\n",
    "0.446632782719\n",
    "</td>\n",
    "<td>\n",
    "0.307793345009\n",
    "</td>\n",
    "<td>\n",
    "0.3644375324\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td rowspan=\"3\">\n",
    "3\n",
    "</td>\n",
    "<td>\n",
    "50\n",
    "</td>\n",
    "<td>\n",
    "0.512295081967\n",
    "</td>\n",
    "<td>\n",
    "0.59694364852\n",
    "</td>\n",
    "<td>\n",
    "0.551389501544\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "100\n",
    "</td>\n",
    "<td>\n",
    "0.488441461596\n",
    "</td>\n",
    "<td>\n",
    "0.467189728959\n",
    "</td>\n",
    "<td>\n",
    "0.477579292745\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "150\n",
    "</td>\n",
    "<td>\n",
    "0.507783145464\n",
    "</td>\n",
    "<td>\n",
    "0.466929911155\n",
    "</td>\n",
    "<td>\n",
    "0.486500385703\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td rowspan=\"3\">\n",
    "4\n",
    "</td>\n",
    "<td>\n",
    "50\n",
    "</td>\n",
    "<td>\n",
    "0.567890691716\n",
    "</td>\n",
    "<td>\n",
    "0.546425636812\n",
    "</td>\n",
    "<td>\n",
    "0.556951423786\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "100\n",
    "</td>\n",
    "<td>\n",
    "0.471113758189\n",
    "</td>\n",
    "<td>\n",
    "0.468047337278\n",
    "</td>\n",
    "<td>\n",
    "0.469575541704\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "150\n",
    "</td>\n",
    "<td>\n",
    "0.472628499791\n",
    "</td>\n",
    "<td>\n",
    "0.50000000000\n",
    "</td>\n",
    "<td>\n",
    "0.485929108485\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td rowspan=\"3\">\n",
    "5\n",
    "</td>\n",
    "<td>\n",
    "50\n",
    "</td>\n",
    "<td>\n",
    "0.614572333685\n",
    "</td>\n",
    "<td>\n",
    "0.501291989664\n",
    "</td>\n",
    "<td>\n",
    "0.552182163188\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "100\n",
    "</td>\n",
    "<td>\n",
    "0.446226415094\n",
    "</td>\n",
    "<td>\n",
    "0.521787093216\n",
    "</td>\n",
    "<td>\n",
    "0.481057716756\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "150\n",
    "</td>\n",
    "<td>\n",
    "0.496774193548\n",
    "</td>\n",
    "<td>\n",
    "0.465364946536\n",
    "</td>\n",
    "<td>\n",
    "0.480556889102\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td rowspan=\"3\">\n",
    "6\n",
    "</td>\n",
    "<td>\n",
    "50\n",
    "</td>\n",
    "<td>\n",
    "0.589261744966\n",
    "</td>\n",
    "<td>\n",
    "0.612273361227\n",
    "</td>\n",
    "<td>\n",
    "0.600547195622\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "100\n",
    "</td>\n",
    "<td>\n",
    "0.549869904597\n",
    "</td>\n",
    "<td>\n",
    "0.459087617668\n",
    "</td>\n",
    "<td>\n",
    "0.500394632991\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "150\n",
    "</td>\n",
    "<td>\n",
    "0.489247311828\n",
    "</td>\n",
    "<td>\n",
    "0.362756264237\n",
    "</td>\n",
    "<td>\n",
    "0.416612164814\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td rowspan=\"3\">\n",
    "7\n",
    "</td>\n",
    "<td>\n",
    "50\n",
    "</td>\n",
    "<td>\n",
    "0.653846153846\n",
    "</td>\n",
    "<td>\n",
    "0.429420505201\n",
    "</td>\n",
    "<td>\n",
    "0.518385650224\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "100\n",
    "</td>\n",
    "<td>\n",
    "0.342857142857\n",
    "</td>\n",
    "<td>\n",
    "0.506181818182\n",
    "</td>\n",
    "<td>\n",
    "0.408810572687\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "150\n",
    "</td>\n",
    "<td>\n",
    "0.399623588457\n",
    "</td>\n",
    "<td>\n",
    "0.367358708189\n",
    "</td>\n",
    "<td>\n",
    "0.3828125\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Results for San Jose:-</h3>\n",
    "<table>\n",
    "<tbody>\n",
    "<tr><th>Partition Number</th><th>Number of members</th><th>Precision</th><th>Recall</th><th>F-measure</th></tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\">1</td>\n",
    "<td>50</td>\n",
    "<td>0.616191904048</td>\n",
    "<td>0.568858131488</td>\n",
    "<td>0.59157970493</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.517844136926</td>\n",
    "<td>0.458413926499</td>\n",
    "<td>0.486320109439</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.616191904048</td>\n",
    "<td>0.568858131488</td>\n",
    "<td>0.59157970493</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\">\n",
    "  2</td>\n",
    "<td>50</td>\n",
    "<td>0.605660377358</td>\n",
    "<td>0.485138539043</td>\n",
    "<td>0.538741258741</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.62962962963</td>\n",
    "<td>0.296511627907</td>\n",
    "<td>0.403162055336</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.538929440389</td>\n",
    "<td>0.427812650893</td>\n",
    "<td>0.476985195155</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\">3</td>\n",
    "<td>50</td>\n",
    "<td>0.768229166667</td>\n",
    "<td>0.431602048281</td>\n",
    "<td>0.552693208431</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.705242334322</td>\n",
    "<td>0.427458033573</td>\n",
    "<td>0.532288167227</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.458050847458</td>\n",
    "<td>0.426598263615</td>\n",
    "<td>0.441765427054</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\">4</td>\n",
    "<td>50</td>\n",
    "<td>0.743690851735</td>\n",
    "<td>0.711698113208</td>\n",
    "<td>0.727342846124</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.777908343126</td>\n",
    "<td>0.433529796988</td>\n",
    "<td>0.55677039529</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.711198428291</td>\n",
    "<td>0.2145820984</td>\n",
    "<td>0.329690346084</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\">5</td>\n",
    "<td>50</td>\n",
    "<td>0.781136638452</td>\n",
    "<td>0.622350674374</td>\n",
    "<td>0.692761394102</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.755555555556</td>\n",
    "<td>0.473607038123</td>\n",
    "<td>0.582244254169</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.518197573657</td>\n",
    "<td>0.19606557377</td>\n",
    "<td>0.28449096099</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td rowspan=\"3\">6</td>\n",
    "<td>50</td>\n",
    "<td>0.580968280467</td>\n",
    "<td>0.395005675369</td>\n",
    "<td>0.47027027027</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.570502431118</td>\n",
    "<td>0.338787295476</td>\n",
    "<td>0.425120772947</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.545180722892</td>\n",
    "<td>0.209612044007</td>\n",
    "<td>0.302802174822</td>\n",
    "</tr>\n",
    "  <tr>\n",
    "<td rowspan=\"3\">7</td>\n",
    "<td>50</td>\n",
    "<td>0.591549295775</td>\n",
    "<td>0.288858321871</td>\n",
    "<td>0.388170055453</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>100</td>\n",
    "<td>0.565723793677</td>\n",
    "<td>0.357894736842</td>\n",
    "<td>0.438426821406</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>150</td>\n",
    "<td>0.551656920078</td>\n",
    "<td>0.16915720263</td>\n",
    "<td>0.258920402562</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "In sum, we propose a recommender system for event based social networks. We resolved the cold start problem associated with the event recommendations by using content based features: location, time, description and group frequency. We got #### results. \n",
    "\n",
    "Further, the next steps would be to use data from other major sites like eventbrite.com, facebook.com and evaluate our recommendation on it. Another work could be to use more features for the system, like: ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] E. Minkov, B. Charrow, J. Ledlie, S. Teller, and T. Jaakkola, Collaborative future event recommendation, In Proc. of CIKM, pages 819-828, 2010.\n",
    "\n",
    "[2] Augusto Q. Macedo, Leandro B. Marinho and Rodrygo L. T. Santos, Context-Aware Event Recommendation in Event-based Social Networks, In Proc. of Recsys, pages 123-130, 2015.\n",
    "\n",
    "[3] H. Khrouf and R. Troncy. Hybrid event recommendation using linked data and user diversity, In Proc. of RecSys, pages 185-192, 2013.\n",
    "\n",
    "[4] A. Q. Macedo and L. B. Marinho, Event recommendation in event-based social networks, In Proc. of Int. Work. on Social Personalization, 2014."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
