{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Report\n",
    "# Project Name - WhatTheRec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Problem Statement\n",
    "In the present scenario, a plethora of events are being held daily at different places and different times. Hence, it is difficult for a user to keep track of all the events and choose between various events which to attend. The problem worsens because the users do not know which events would be interesting and relevant to them. Hence, it is important that an event sharing social network use recommenders to suggest relevant and interesting events to its users which help them choose between various events. While recommending events, another problem whiich arises is that of unseen data. We do not know for sure which users will attend what events, especially in the case of new users. This is often called the cold start problem. There are many Event Based Social Network (EBSN) websites like meetup.com, eventbrite.com etc., which could deploy this algorithm in order to successfully suggest interesting and relevant events to its users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Work\n",
    "There has been some work done in hybrid approaches in event recommendation by Minkov et al. [1]. This paper demonstrates collaborative filtering on a dataset of academic events. Our implementation of the recommender system follows [2], which also utilizes other signals such as a group of users, location, and temporal preferences. Khrouf and Troncy [3] for recommending music related events, utilized category information about different artists from a well-known source. But this approach fails when we do not have this information about every event, as events can be across different domains. Our implementation takes into account RSVP and group information and other contextual data. Recent works [4] have shown that pure matrix factorization (based only on user-event interactions) performs poorly on EBSN data in comparison to other methods due to a high level of the sparsity of these datasets. As per experiments carried out, state-of-the-art matrix factorization algorithms did not perform better than simple collaborative filtering algorithms such as user-based k-NN. Thus the focus is on considering the explicit features than the latent ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach & Methods\n",
    "\n",
    "Data Acquisition - Initially we fetched data from meetup.com using their public apis. As we started developing, we realized the data was too less as this data is super sparse in nature. So, when we again starting getting data, they changed their apis and a lot of them were broken. So, we decided to contact the the researchers and got the raw data from them. We cleaned/parsed the data and used that for our project. We used data from Jan 1, 2010 - Jan 2014. \n",
    "The data contains the following information:\n",
    "1. Events: event id, description of event, event group, users who rsvped to this event.\n",
    "2. Members: member id, lat long\n",
    "3. Groups: events organized by the group, members involved in the group\n",
    "\n",
    "We, then, divided the data into timestamps of 6 months. For example, one timestamp would be July 1, 2010. Then, the first 6 months were used for training and the last 6 months for testing. We extracted the following features to recommend events: time, location, description and group frequency of event. \n",
    "\n",
    "a. Content-based - We formed a model of a user using the description of the past events he attended. Then found similarity of potential events with the user model. \n",
    "\n",
    "b. Location-based - We fitted a gausian distribution to the location of the past events of a user. Then found the probability of new event according to the curve. \n",
    "\n",
    "c. Group-Frequency - The intuition here is that the likelihood of the target user attending an event depends on the number of events this user attended in the group that event belongs to. \n",
    "\n",
    "d. Time-Aware - Another important factor that affect users' decision on attending an event is when the event occurs. We capture this intuition by assuming that users that attended events in the past at certain days of the week and at certain hours of the day will likely attend events with a similar temporal profile in the future.\n",
    "\n",
    "Now, that we have built a model of the data, we then computed similarity scores for each member with the events that they had rsvp'd. Events in the first half were used to train the model and the events in the second half were used to test it. Note that we knew the events which the members had rsvp'd for the both the halves. So, the rsvp's for the second half were used to evaluate the model. Here's our index.py file, which is what you need run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate the list of best users who have the most RSVP's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you run our recommender index file. Type the name of cities you want to run the recommender on: \n",
    "Note: We have data from only Chicago, San jose and Phoenix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Parameters Below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('src')\n",
    "city = 'LCHICAGO' # or 'LSAN JOSE', or 'LPHOENIX'\n",
    "algolist = ['rf']\n",
    "number_of_members = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name MLPClassifier",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9c7f355881e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation_recommender\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLocationRecommender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgroup_frequency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrp_freq_recommender\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGrpFreqRecommender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhybrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_to_rank\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLearningToRank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abhishek/ISR/Recommender_for_event_based_social_network/src/hybrid/learning_to_rank.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name MLPClassifier"
     ]
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "import argparse\n",
    "from partition import *\n",
    "from content.content_recommender import ContentRecommender\n",
    "from temporal.time_recommender import TimeRecommender\n",
    "from location.location_recommender import LocationRecommender\n",
    "from group_frequency.grp_freq_recommender import GrpFreqRecommender\n",
    "from hybrid.learning_to_rank import LearningToRank\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "#number of seconds in 6 months\n",
    "train_data_interval = ((364 / 2) * 24 * 60 * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Testing using Content Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def content_classifier(training_repo, test_repo, timestamp, simscores, test_members):\n",
    "\n",
    "    training_events_dict = training_repo['members_events']\n",
    "    potential_events = list(test_repo['events_info'].keys())\n",
    "\n",
    "    contentRecommender = ContentRecommender()\n",
    "    contentRecommender.train(training_events_dict, training_repo)\n",
    "    test_events_vec = contentRecommender.get_test_events_wth_description(test_repo, potential_events)\n",
    "\n",
    "    #TEST FOR BEST USERS\n",
    "    for member in test_members:\n",
    "         contentRecommender.test(member, potential_events, test_events_vec, simscores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Testing using Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_classifier(training_repo, test_repo, timestamp, simscores, test_members):\n",
    "\n",
    "    training_events_dict = training_repo['members_events']\n",
    "    potential_events = list(test_repo['events_info'].keys())\n",
    "\n",
    "    timeRecommender = TimeRecommender()\n",
    "    timeRecommender.train(training_events_dict, training_repo)\n",
    "    test_events_vec = timeRecommender.get_test_event_vecs_with_time(test_repo, potential_events)\n",
    "\n",
    "    #TEST FOR BEST USERS\n",
    "    for member in test_members:\n",
    "         timeRecommender.test(member, potential_events, test_events_vec, simscores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Testing using Location feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loc_classifier(training_repo, test_repo, timestamp, simscores, test_members):\n",
    "    training_events_dict = training_repo['members_events']\n",
    "    potential_events = list(test_repo['events_info'].keys())\n",
    "\n",
    "    locationRecommender = LocationRecommender()\n",
    "    locationRecommender.train(training_events_dict, training_repo)\n",
    "\n",
    "    #TEST FOR BEST USERS\n",
    "    for member in test_members:\n",
    "        locationRecommender.test(member, potential_events, test_repo, simscores)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Testing using Group Frequency feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def grp_freq_classifier(training_repo, test_repo, timestamp, simscores, test_members):\n",
    "    training_events_dict = training_repo['members_events']\n",
    "    potential_events = list(test_repo['events_info'].keys())\n",
    "\n",
    "    grp_freq_recommender = GrpFreqRecommender()\n",
    "    grp_freq_recommender.train(training_events_dict, training_repo)\n",
    "    \n",
    "    for member in test_members:\n",
    "         grp_freq_recommender.test(member, potential_events, test_repo, simscores)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, extract the data from csv file into python dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_and_run_local_crawler():\n",
    "    if os.path.isdir(\"../crawler/cities/LCHICAGO\") and os.path.isdir(\"../crawler/cities/LSAN JOSE\")\\\n",
    "            and os.path.isdir(\"../crawler/cities/LPHOENIX\"):\n",
    "        if len(os.listdir(\"../crawler/cities/LCHICAGO\")) >= 5 and len(os.listdir(\"../crawler/cities/LSAN JOSE\"))>=5\\\n",
    "                and len(os.listdir(\"../crawler/cities/LPHOENIX\")) >= 5:\n",
    "            return\n",
    "    os.chdir(\"../crawler\")\n",
    "    os.system(\"python local_crawler.py\")\n",
    "    os.chdir(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_script(number_of_members):\n",
    "    os.chdir(\"scripts\")\n",
    "    os.system(\"python script.py --number \" + str(number_of_members))\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building best user database ...\n",
      "Best users extracted.\n",
      "Partition at timestamp "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0f0576e7282c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-0f0576e7282c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtest_members\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_members\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnumber_of_members\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Partition at timestamp \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" are : \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mtraining_repo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_repo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_partitioned_repo_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Partitioned Repo retrieved for timestamp : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    check_and_run_local_crawler()\n",
    "    print \"Building best user database ...\"\n",
    "    run_script(number_of_members)\n",
    "    print \"Best users extracted.\"\n",
    "\n",
    "    group_members, group_events, event_group = load_groups(\"../crawler/cities/\" + city + \"/group_members.json\",\n",
    "                                                            \"../crawler/cities/\" + city + \"/group_events.json\")\n",
    "    events_info = load_events(\"../crawler/cities/\" + city + \"/events_info.json\")\n",
    "    members_info = load_members(\"../crawler/cities/\" + city + \"/members_info.json\")\n",
    "    member_events = load_rsvps(\"../crawler/cities/\" + city + \"/rsvp_events.json\")\n",
    "\n",
    "    repo = dict()\n",
    "    repo['group_events'] = group_events\n",
    "    repo['group_members'] = group_members\n",
    "    repo['events_info'] = events_info\n",
    "    repo['members_info'] = members_info\n",
    "    repo['members_events'] = member_events\n",
    "    repo['event_group'] = event_group\n",
    "    \n",
    "    #simscores_across_features is a dictionary to store similarity score obtained for each feature\n",
    "    #for each member and for a given event. For example in case of content classifer we will\n",
    "    #access the similarity score as follows: simscores['content_classifier'][member_id][event_id].\n",
    "    #We will pass only a specific subdictionary (Ex: simscores['content_classifier']) to the\n",
    "    #classifier functions, which will work on them and populate them.\n",
    "    \n",
    "    simscores_across_features = defaultdict(lambda :defaultdict(lambda :defaultdict(lambda :0)))\n",
    "    hybrid_simscores = defaultdict(lambda :defaultdict(lambda :0))\n",
    "\n",
    "    start_time = 1262304000 # 1st Jan 2010\n",
    "    end_time = 1388534400 # 1st Jan 2014\n",
    "    timestamps = get_timestamps(start_time, end_time)\n",
    "    timestamps = sorted(timestamps, reverse=True)\n",
    "    count_partition = 1\n",
    "\n",
    "    f_temp = open('temp_result.txt', 'w+')\n",
    "    f_temp.write(\"Using classification algorithms : \" + str(algolist) + \" and number of members as : \" +\\\n",
    "                 str(number_of_members) + \"\\n\")\n",
    "\n",
    "    for t in timestamps:\n",
    "        start_time = t - train_data_interval\n",
    "        end_time = t + train_data_interval\n",
    "        test_members = []\n",
    "        f = open(\"scripts/\"+city + \"_best_users_\" + str(start_time) + \"_\" + str(end_time) + \".txt\", \"r\")\n",
    "        for users in f:\n",
    "            test_members.extend(users.split())\n",
    "        f.close()\n",
    "        test_members = test_members[:number_of_members]\n",
    "        print \"Partition at timestamp \", datetime.datetime.fromtimestamp(t), \" are : \"\n",
    "        training_repo, test_repo = get_partitioned_repo_wrapper(t, repo)\n",
    "        print \"Partitioned Repo retrieved for timestamp : \", datetime.datetime.fromtimestamp(t)\n",
    "\n",
    "        training_members = set(training_repo['members_events'].keys())\n",
    "        test_members =  training_members.intersection(set(test_members))\n",
    "        test_members = list(test_members)\n",
    "        \n",
    "        #Calling content based classifer train and test functions from here. Pass the repo\n",
    "        #as an argument to these functions.\n",
    "        start = time.clock()\n",
    "        print \"Starting Content Classifier\"\n",
    "        content_classifier(training_repo, test_repo, t, simscores_across_features['content_classifier'],\\\n",
    "                           test_members)\n",
    "        print \"Completed Content Classifier in \", time.clock() - start, \" seconds\"\n",
    "\n",
    "        start = time.clock()\n",
    "        print \"Starting Time Classifier\"\n",
    "        time_classifier(training_repo, test_repo, t, simscores_across_features['time_classifier'], test_members)\n",
    "        print \"Completed Time Classifier in \", time.clock() - start, \" seconds\"\n",
    "\n",
    "        start = time.clock()\n",
    "        print \"Starting Location Classifier\"\n",
    "        loc_classifier(training_repo, test_repo, t, simscores_across_features['location_classifier'], test_members)\n",
    "        print \"Completed Location Classifier in \", time.clock() - start, \" seconds\"\n",
    "\n",
    "        start = time.clock()\n",
    "        print \"Starting Group Frequency Classifier\"\n",
    "        grp_freq_classifier(training_repo, test_repo, t, simscores_across_features['grp_freq_classifier'],\\\n",
    "                            test_members)\n",
    "        print \"Completed Group Frequency Classifier in \", time.clock() - start, \" seconds\"\n",
    "\n",
    "        f_temp.write(\"============== Starting classification for partition : \" +  str(count_partition) +\\\n",
    "                     \" ===================\\n\")\n",
    "        learningToRank = LearningToRank()\n",
    "        learningToRank.learning(simscores_across_features, test_repo[\"events_info\"].keys(), \\\n",
    "                                test_repo[\"members_events\"], test_members, f_temp, algolist, \\\n",
    "                                number_of_members, count_partition)\n",
    "        f_temp.write(\"============== Starting classification for partition : \" +  str(count_partition) +\\\n",
    "                     \" ===================\\n\")\n",
    "        \n",
    "        count_partition += 1\n",
    "    \n",
    "    f_temp.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We divided an year's data in 2 slots. So we build the model of the user from the rsvpd events in the first slot, and then for each of the event in the next slot, do the recommendation. We do a k fold setup to evaluate recommendations. For 80% of the users, we train the classifier and then calculate precision, recall and f-score for the remaining 20% of the users.\n",
    "\n",
    "For a new user(who didn't attend any event in the fist slot), we recommend the event which occurs closest to user's location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "In sum, we propose a recommender system for event based social networks. We resolved the cold start problem associated with the event recommendations by using content based features: location, time, description and group frequency. We got #### results. \n",
    "\n",
    "Further, the next steps would be to use data from other major sites like eventbrite.com, facebook.com and evaluate our recommendation on it. Another work could be to use more features for the system, like: ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] E. Minkov, B. Charrow, J. Ledlie, S. Teller, and T. Jaakkola, Collaborative future event recommendation, In Proc. of CIKM, pages 819-828, 2010.\n",
    "\n",
    "[2] Augusto Q. Macedo, Leandro B. Marinho and Rodrygo L. T. Santos, Context-Aware Event Recommendation in Event-based Social Networks, In Proc. of Recsys, pages 123-130, 2015.\n",
    "\n",
    "[3] H. Khrouf and R. Troncy. Hybrid event recommendation using linked data and user diversity, In Proc. of RecSys, pages 185-192, 2013.\n",
    "\n",
    "[4] A. Q. Macedo and L. B. Marinho, Event recommendation in event-based social networks, In Proc. of Int. Work. on Social Personalization, 2014."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
